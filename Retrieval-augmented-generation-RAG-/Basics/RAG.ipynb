{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "import pinecone\n",
    "from tqdm.auto import tqdm\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup the OpenAI key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") \n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the PDF and extract it to a text file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text length: 89062 characters\n"
     ]
    }
   ],
   "source": [
    "pdf_path = 'MORBO.pdf'\n",
    "\n",
    "\n",
    "pdf_text = ''\n",
    "with open(pdf_path, 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    for page in reader.pages:\n",
    "        pdf_text += page.extract_text() or ''\n",
    "\n",
    "with open('extracted_text.txt', 'w', encoding='utf-8') as text_file:\n",
    "    text_file.write(pdf_text)\n",
    "\n",
    "print(f\"Extracted text length: {len(pdf_text)} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup Pinecone as the Vector DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n", 
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", region=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Indexfile to store the vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'llama-2-rag'\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,  # dimensionality of ada 002\n",
    "        metric='dotproduct',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the textfile into a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text        doi  chunk-id  \\\n",
      "0  Multi-Objective Bayesian Optimization over Hig...  doi_value         0   \n",
      "1  coordinated strategy. We show that MORBO signi...  doi_value         1   \n",
      "2  maximizing the number of common gauge parts [K...  doi_value         2   \n",
      "3  general, and sample-efﬁcient approach for “bla...  doi_value         3   \n",
      "4  groundwater remediation [Akhtar and Shoemaker,...  doi_value         4   \n",
      "\n",
      "         source        title  \n",
      "0  source_value  title_value  \n",
      "1  source_value  title_value  \n",
      "2  source_value  title_value  \n",
      "3  source_value  title_value  \n",
      "4  source_value  title_value  \n"
     ]
    }
   ],
   "source": [
    "with open('extracted_text.txt', 'r', encoding='utf-8') as file:\n",
    "    pdf_text = file.read()\n",
    "\n",
    "# Split text into chunks\n",
    "chunk_size = 1000  # Define the chunk size\n",
    "chunks = textwrap.wrap(pdf_text, chunk_size)\n",
    "\n",
    "# Create a DataFrame from the chunks\n",
    "data = pd.DataFrame({\n",
    "    'text': chunks,\n",
    "    'doi': ['doi_value']*len(chunks),  # Dummy values; replace with actual data if available\n",
    "    'chunk-id': range(len(chunks)),    # Sequential chunk ids\n",
    "    'source': ['source_value']*len(chunks),  # Dummy values; replace with actual data if available\n",
    "    'title': ['title_value']*len(chunks)  # Dummy values; replace with actual data if available\n",
    "})\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process text and add to Pinecone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4bf2f3e84e4153bd13c9fd206e3745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i + batch_size)\n",
    "    # Get batch of data\n",
    "    batch = data.iloc[i:i_end]\n",
    "    # Generate unique ids for each chunk\n",
    "    ids = [f\"{x['doi']}-{x['chunk-id']}\" for _, x in batch.iterrows()]\n",
    "    # Get text to embed\n",
    "    texts = [x['text'] for _, x in batch.iterrows()]\n",
    "    # Embed text\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # Get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'text': x['text'],\n",
    "         'source': x['source'],\n",
    "         'title': x['title']} for _, x in batch.iterrows()\n",
    "    ]\n",
    "    # Add to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain_community\\vectorstores\\pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone(\n",
    "    index, embed_model.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='from most existing methods. The signiﬁcance of MORBO is that it is the ﬁrst multi- objective BO method that scales to hundreds of tunable parameters and thousands of evaluations, a setting where practitioners have previously had to fall back on alterna- tive methods with much lower sample-efﬁciency, such as NSGA-II. Our comprehensive evaluation demonstrates that MORBO yields order-of-magnitude savings in terms of time and resources compared to state-of-the-art methods on chal- lenging high-dimensional multi-objective problems. 2 BACKGROUND 2.1 PRELIMINARIES 2.1.1 Multi-Objective Optimization In multi-objective optimization (MOO), the goal is to max- imize (without loss of generality) a vector-valued objec- tive functionf(x) = [f(1)(x);:::;f(M)(x)]2RM, where M\\x152while satisfying black-box constraints g(x)\\x1502 RVwhereV\\x150,x2X\\x1a Rd, andXis a compact set. Usually, there is no single solution x\\x03that simultaneously maximizes all Mobjectives and satisﬁes all Vconstraints.Hence, objective vectors', metadata={'source': 'source_value', 'title': 'title_value'}),\n",
       " Document(page_content='coordinated strategy. We show that MORBO signiﬁcantly ad- vances the state-of-the-art in sample efﬁciency for several high-dimensional synthetic problems and real world applications, including an optical dis- play design problem and a vehicle design prob- lem with 146and222parameters, respectively. On these problems, where existing BO algorithms fail to scale and perform well, MORBO provides prac- titioners with order-of-magnitude improvements in sample efﬁciency over the current approach. 1 INTRODUCTION The challenge of identifying optimal trade-offs between multiple complex objective functions is pervasive in many ﬁelds, including machine learning [Sener and Koltun, 2018], science [Gopakumar et al., 2018], and engineering [Marler and Arora, 2004, Mathern et al., 2021]. For instance, Mazda recently proposed a vehicle design problem in which the goal is to optimize the widths of 222structural parts in orderto minimize the total weight of three different vehicles while simultaneously', metadata={'source': 'source_value', 'title': 'title_value'}),\n",
       " Document(page_content='collaborative multi-trust-region approach with scalable local modeling, MORBO scales gracefully to high- dimensional problems and high-throughput settings. In a comprehensive experimental evaluation, we showed that MORBO allows us to effectively tackle important real-world problems that were previously out of reach for existing BO methods . We showed that MORBO achieves substantial im- provements in sample efﬁciency compared to existing state- of-the-art methods such as evolutionary algorithms. Due to the lack of alternatives, NSGA-II has been the method of choice for many practitioners, and we expect MORBO to provide practitioners with signiﬁcant savings in terms of time and resources across the many disciplines that require solving challenging optimization problems. However, there are some limitations to our method. Al- though MORBO can handle a large number of black-box constraints, using hypervolume-based acquisition means the computational complexity scales poorly with the number', metadata={'source': 'source_value', 'title': 'title_value'})]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is MORBO?\"\n",
    "\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # get top 3 results from knowledge base\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # feed into an augmented prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the contexts below, answer the query.\n",
      "\n",
      "    Contexts:\n",
      "    from most existing methods. The signiﬁcance of MORBO is that it is the ﬁrst multi- objective BO method that scales to hundreds of tunable parameters and thousands of evaluations, a setting where practitioners have previously had to fall back on alterna- tive methods with much lower sample-efﬁciency, such as NSGA-II. Our comprehensive evaluation demonstrates that MORBO yields order-of-magnitude savings in terms of time and resources compared to state-of-the-art methods on chal- lenging high-dimensional multi-objective problems. 2 BACKGROUND 2.1 PRELIMINARIES 2.1.1 Multi-Objective Optimization In multi-objective optimization (MOO), the goal is to max- imize (without loss of generality) a vector-valued objec- tive functionf(x) = [f(1)(x);:::;f(M)(x)]2RM, where M\u00152while satisfying black-box constraints g(x)\u001502 RVwhereV\u00150,x2X\u001a Rd, andXis a compact set. Usually, there is no single solution x\u0003that simultaneously maximizes all Mobjectives and satisﬁes all Vconstraints.Hence, objective vectors\n",
      "coordinated strategy. We show that MORBO signiﬁcantly ad- vances the state-of-the-art in sample efﬁciency for several high-dimensional synthetic problems and real world applications, including an optical dis- play design problem and a vehicle design prob- lem with 146and222parameters, respectively. On these problems, where existing BO algorithms fail to scale and perform well, MORBO provides prac- titioners with order-of-magnitude improvements in sample efﬁciency over the current approach. 1 INTRODUCTION The challenge of identifying optimal trade-offs between multiple complex objective functions is pervasive in many ﬁelds, including machine learning [Sener and Koltun, 2018], science [Gopakumar et al., 2018], and engineering [Marler and Arora, 2004, Mathern et al., 2021]. For instance, Mazda recently proposed a vehicle design problem in which the goal is to optimize the widths of 222structural parts in orderto minimize the total weight of three different vehicles while simultaneously\n",
      "collaborative multi-trust-region approach with scalable local modeling, MORBO scales gracefully to high- dimensional problems and high-throughput settings. In a comprehensive experimental evaluation, we showed that MORBO allows us to effectively tackle important real-world problems that were previously out of reach for existing BO methods . We showed that MORBO achieves substantial im- provements in sample efﬁciency compared to existing state- of-the-art methods such as evolutionary algorithms. Due to the lack of alternatives, NSGA-II has been the method of choice for many practitioners, and we expect MORBO to provide practitioners with signiﬁcant savings in terms of time and resources across the many disciplines that require solving challenging optimization problems. However, there are some limitations to our method. Al- though MORBO can handle a large number of black-box constraints, using hypervolume-based acquisition means the computational complexity scales poorly with the number\n",
      "\n",
      "    Query: What is MORBO?\n"
     ]
    }
   ],
   "source": [
    "print(augment_prompt(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand about Entropy in Machine Learning. give latex code\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MORBO is a multi-objective Bayesian optimization method that is significant because it is the first method that can scale to handling hundreds of tunable parameters and thousands of evaluations. It outperforms existing methods in terms of time and resources, providing order-of-magnitude savings on challenging high-dimensional multi-objective problems. MORBO incorporates a collaborative multi-trust-region approach with scalable local modeling, allowing it to tackle high-dimensional problems and high-throughput settings effectively. It significantly advances the state-of-the-art in sample efficiency and provides practitioners with substantial improvements over existing methods such as evolutionary algorithms.\n"
     ]
    }
   ],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(query)\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context provided, BO stands for Bayesian Optimization. It is a technique used in optimization problems to find the optimal set of parameters for a given objective function while minimizing the number of evaluations needed. Bayesian Optimization uses probabilistic models to approximate the objective function and guide the search for the best set of parameters.\n"
     ]
    }
   ],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=\"what is bo?\"\n",
    ")\n",
    "\n",
    "res = chat(messages + [prompt])\n",
    "print(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
